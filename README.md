# ğŸš€ AWS Monitoring & Alerting Stack
### Prometheus | Grafana | Alertmanager | Node Exporter | PagerDuty

This project sets up an end-to-end monitoring and alerting system for AWS EC2 servers.  
The stack collects metrics using Node Exporter, scrapes them using Prometheus, visualizes them in Grafana dashboards, and sends incident alerts to PagerDuty when thresholds are crossed.

---

## ğŸ“‚ Components Used
| Tool | Purpose |
|------|---------|
| Prometheus | Metrics scraping & storage |
| Node Exporter | Server metrics exporter |
| Grafana | Visualization & dashboards |
| Alertmanager | Alert routing |
| PagerDuty | Incident notifications |

---

## ğŸ— Architecture
Node Exporter  â†’  Prometheus  â†’  Alertmanager  â†’  PagerDuty Alerts â†“ Grafana UI


---

## ğŸš€ Installation (EC2)
```bash
git clone https://github.com/<your-username>/Monitoring-Alerting-Using-Grafana-Prometheus.git
cd Monitoring-Alerting-Using-Grafana-Prometheus
chmod +x setup.sh
sudo ./setup.sh


---

ğŸ”¥ Prometheus Alerts Included

1ï¸âƒ£ Instance Down Alert

ALERT InstanceDown
  IF up == 0
  FOR 1m
  LABELS { severity="critical" }
  ANNOTATIONS {
    summary="Instance down: {{ $labels.instance }}",
    description="The instance has been unreachable for more than 1 minute."
  }

2ï¸âƒ£ High CPU Usage Alert

ALERT HighCPUUsage
  IF (100 - avg by(instance)(rate(node_cpu_seconds_total{mode="idle"}[2m]) * 100)) > 60
  FOR 2m
  LABELS { severity="critical" }
  ANNOTATIONS {
    summary="High CPU detected",
    description="CPU usage above 60% for more than 2 minutes."
  }

3ï¸âƒ£ High Memory Usage Alert

ALERT HighMemoryUsage
  IF (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 75
  FOR 2m
  LABELS { severity="warning" }
  ANNOTATIONS {
    summary="High memory detected",
    description="Memory usage greater than 75%."
  }

4ï¸âƒ£ High Disk Usage Alert

ALERT HighDiskUsage
  IF (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 80
  FOR 3m
  LABELS { severity="critical" }
  ANNOTATIONS {
    summary="High disk usage detected",
    description="Disk usage greater than 80%."
  }

5ï¸âƒ£ Unauthorized Requests Alert

ALERT UnauthorizedRequests
  IF increase(http_requests_total{status=~"401|403"}[5m]) > 0
  LABELS { severity="warning" }
  ANNOTATIONS {
    summary="Unauthorized requests detected",
    description="Requests with status 401 or 403 detected in last 5 minutes."
  }


---

ğŸ“Š Grafana Dashboard Setup

Grafana â†’ Dashboards â†’ Import â†’ Enter dashboard ID: 1860
Select datasource â†’ prometheus


---

ğŸ”” PagerDuty Integration

Alertmanager uses PagerDuty webhook to trigger incidents.

Alertmanager file location:

/etc/alertmanager/alertmanager.yml

Modify the routing:

receivers:
  - name: pagerduty
    pagerduty_configs:
      - routing_key: "<YOUR_PAGERDUTY_INTEGRATION_KEY>"


---

ğŸ›‘ Service Commands

sudo systemctl restart prometheus
sudo systemctl restart alertmanager
sudo systemctl restart grafana-server
sudo systemctl restart node_exporter  # only on node server


---

ğŸ§ª Test Alerts

Alert	How to trigger

High CPU	yes > /dev/null &
Stop high CPU	pkill yes
Disk full	fallocate -l 5G test.img
Instance down	Stop node_exporter service



---

ğŸ“Œ Project Outcome

âœ” Full AWS monitoring setup
âœ” Auto-target discovery using EC2 SD
âœ” Grafana dashboards showing live metrics
âœ” PagerDuty incidents on failures
âœ” Production-ready monitoring automation


---

ğŸ§‘â€ğŸ’» Author

Shaik Tahir Basha
DevOps & Cloud Engineer

ğŸŒ GitHub: https://github.com/Tahirshaik706
ğŸ”— LinkedIn: https://www.linkedin.com/in/shaik-tahir-basha-6b5018270

---
